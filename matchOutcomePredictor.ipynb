{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Match Outcome Predictor\n",
    "\n",
    "Script to generate the outcome of a given match using the parameters available of a started match (e.g. a match with a NULL score), using machine learning. Algorithm is applied to the dbo.matches table in the AOE2 SQL database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyodbc\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to database\n",
    "sql_conn = pyodbc.connect(DRIVER=\"{SQL Server Native Client 11.0}\", \n",
    "                          SERVER=\"localhost\\SQLEXPRESS\", \n",
    "                          DATABASE=\"AOE2\", \n",
    "                          Trusted_Connection=\"yes\") \n",
    "\n",
    "cursor = sql_conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve data from database\n",
    "cursor.execute(\"SELECT TOP 100000 * FROM matchPredictions\")\n",
    "data = cursor.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert into dataframe\n",
    "raw = pd.DataFrame([[j for j in i] for i in data],columns=['ratingDifference','playerMatchup','civMatchup','winner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1369"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create columns for onehot encoding\n",
    "civNum = 37 # number of civs in the game\n",
    "\n",
    "matchString=[]\n",
    "\n",
    "for i in range(civNum):\n",
    "    for j in range(civNum):\n",
    "        \n",
    "        matchString.append(str(i)+':'+str(j))\n",
    "\n",
    "len(matchString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform onehot encoding on matchups\n",
    "onehot = OneHotEncoder(dtype=np.int, sparse=True)\n",
    "\n",
    "X = pd.DataFrame(\n",
    "                onehot.fit_transform(raw[['civMatchup']]).toarray(),\n",
    "                columns=matchString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['ratingDifference'] = raw.ratingDifference\n",
    "y = raw.winner\n",
    "\n",
    "# free up memory\n",
    "del raw\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into training and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=0)\n",
    "\n",
    "# normalise the ratingDifference feature\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler(copy=False)\n",
    "\n",
    "# split like this to avoid creating another memory-intensive variable\n",
    "ratingDiffTrain = X_train['ratingDifference']\n",
    "ratingDiffTest  = X_test['ratingDifference']\n",
    "\n",
    "ratingDiffTrain.is_copy = None\n",
    "ratingDiffTest.is_copy = None\n",
    "\n",
    "X_train.drop('ratingDifference',axis=1,inplace=True)\n",
    "X_test.drop( 'ratingDifference',axis=1,inplace=True)\n",
    "\n",
    "X_train['ratingDifference'] = scaler.fit_transform(ratingDiffTrain[:,None])\n",
    "X_test['ratingDifference']  = scaler.transform(ratingDiffTest[:,None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a model\n",
    "from sklearn.svm import SVC\n",
    "linRidge = SVC(kernel='linear',C=1.0).fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linRidge.score(X_test_scaled,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff_rating = list(zip(X.columns,linRidge.coef_[0]))\n",
    "most_important_features = sorted(coeff_rating, key=lambda x: x[-1], reverse=True)\n",
    "\n",
    "print(most_important_features[:4])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
